---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: argo-cd
spec:
  interval: 2m
  chart:
    spec:
      chart: argo-cd
      version: 7.3.7
      sourceRef:
        kind: HelmRepository
        name: argocd
  values:
    global:
      domain: argocd.${INGRESS_DOMAIN}
    configs:
      cm:
        kustomize.buildOptions: --enable-helm
        kustomize.path.v5.0.1: /usr/local/bin/kustomize
        kustomize.buildOptions.v5.0.1: --enable-helm
        resource.exclusions: |
          - apiGroups:
              - cilium.io
            kinds:
              - CiliumIdentity
            clusters:
              - "*"
        oidc.config: |
          name: Okta
          issuer: https://dev-32284334.okta.com/oauth2/ausit8azz8ZERL66L5d7
          clientID: $argocd-oidc-secret:oidc.clientID
          # cliClientID: $argocd-oidc-secret:oidc.cliClientID
          clientSecret: $argocd-oidc-secret:oidc.clientSecret
          requestedScopes: ["openid", "profile", "email", "groups"]
          skipAudienceCheckWhenTokenHasNoAudience: true
          requestedIDTokenClaims: {"groups": {"essential": true}}
        # accounts.dogfooding-gha: apiKey
      params:
        # Repo server RPC call timeout seconds. (default 60)
        controller.repo.server.timeout.seconds: "300"
        # Repo server RPC call timeout seconds. (default 60)
        server.repo.server.timeout.seconds: "300"
      repositories:
        argoproj-helm:
          type: helm
          name: argo-cd
          url: https://argoproj.github.io/argo-helm
      rbac:
        policy.default: role:admin
        policy.csv: ""
        scopes: '[groups]'
    dex:
      enabled: false
    server:
      env:
        - name: ARGOCD_GRPC_KEEP_ALIVE_MIN
          value: "30s"
      extraArgs:
        - --request-timeout=300s
        - --insecure
        - --repo-server-timeout-seconds=300
      resources:
        requests:
          cpu: 500m
          memory: 256Mi
        limits:
          memory: 256Mi
      ingress:
        enabled: true
        tls: true
        # ingressClassName: "nginx"
        annotations:
          # https://argo-cd.readthedocs.io/en/stable/operator-manual/ingress/#ssl-passthrough-with-cert-manager-and-lets-encrypt
          cert-manager.io/cluster-issuer: global-issuer
          # nginx.ingress.kubernetes.io/ssl-passthrough: "true"
          # nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
          # nginx.ingress.kubernetes.io/proxy-connect-timeout: "600"
          # nginx.ingress.kubernetes.io/proxy-read-timeout: "96000"
          # nginx.ingress.kubernetes.io/proxy-send-timeout: "96000"

    controller:
      metrics:
        enabled: true
        serviceMonitor:
          enabled: true
      # resources:
      #   requests:
      #     cpu: 2.5
      #     memory: 2Gi
      #   limits:
      #     memory: 2Gi

    applicationSet:
      metrics:
        enabled: true
        serviceMonitor:
          enabled: true
      resources:
        requests:
          cpu: 25m
          memory: 128Mi
        limits:
          memory: 128Mi

    repoServer:
      metrics:
        enabled: true
        serviceMonitor:
          enabled: true
      # initContainers:
      #   # Setup an init-container to login to private docker registries with 'helm registry login'.
      #   # This is needed because currently,  the upstream methods of configuring
      #   # authentication to private helm repositories does not work with
      #   # kustomize's helmCharts feature and OCI chart repositories.
      #   - name: registry-auth
      #     # copied from https://github.com/argoproj/argo-helm/blob/main/charts/argo-cd/templates/argocd-repo-server/deployment.yaml
      #     image: '{{ default .Values.global.image.repository .Values.repoServer.image.repository }}:{{ default (include "argo-cd.defaultTag" .) .Values.repoServer.image.tag }}'
      #     env:
      #       - name: HELM_CONFIG_HOME
      #         value: /helm-auth
      #       # Configure where helm looks for OCI registry credentials.
      #       - name: HELM_REGISTRY_CONFIG
      #         value: /helm-auth/config.json
      #       - name: QUAY_USERNAME
      #         valueFrom:
      #           secretKeyRef:
      #             name: argocd-quay-helm-credentials
      #             key: username
      #       - name: QUAY_PASSWORD
      #         valueFrom:
      #           secretKeyRef:
      #             name: argocd-quay-helm-credentials
      #             key: password
      #     volumeMounts:
      #       # mount the directory that helm will use in the main container
      #       - mountPath: /helm-auth
      #         name: registry-auth-dir
      #     command:
      #       - /bin/bash
      #       - -exc
      #       - 'helm registry login quay.io --username $QUAY_USERNAME --password $QUAY_PASSWORD'
      # env:
      #   - name: HELM_REGISTRY_CONFIG
      #     value: /helm-auth/config.json
      #   - name: ARGOCD_GRPC_KEEP_ALIVE_MIN
      #     value: "30s"
      # volumes:
      #   - name: registry-auth-dir
      #     emptyDir: {}
      # volumeMounts:
      #   # contains config.json with OCI registry credentials
      #   - mountPath: /helm-auth
      #     name: registry-auth-dir
      # containerSecurityContext:
      #   # required for helm to untar the OCI charts
      #   readOnlyRootFilesystem: true
      resources:
        requests:
          cpu: 1
          memory: 1Gi
        limits:
          memory: 1Gi

    notifications:
      metrics:
        enabled: true
        serviceMonitor:
          enabled: true
      resources:
        requests:
          cpu: 25m
          memory: 128Mi
        limits:
          memory: 128Mi

    redis:
      metrics:
        enabled: true
        serviceMonitor:
          enabled: true
      resources:
        requests:
          cpu: 25m
          memory: 512Mi
        limits:
          memory: 512Mi

