grafana:
  resources:
    requests:
      cpu: 500m
      memory: 300Mi
    limits:
      memory: 800Mi

  plugins:
    - isovalent-hubble-datasource
    - isovalent-hubbleprocessancestry-panel

  grafana.ini:
    dataproxy:
      timeout: 300

  persistence:
    enabled: false 

  # needed since we're using a PVC and can't mount it to more than one pod at once
  deploymentStrategy:
    type: Recreate

  # admin:
  #   existingSecret: "grafana-credentials"
  #   userKey: admin-user
  #   passwordKey: admin-password

  serviceMonitor:
    enabled: true

  sidecar:
    dashboards:
      enabled: true
      label: grafana_dashboard
      folderAnnotation: grafana_folder
      provider:
        foldersFromFilesStructure: true

  additionalDataSources:
    - name: Loki
      type: loki
      uid: loki
      url: http://loki-read.monitoring:3100

  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: 'default'
          orgId: 1
          folder: 'Default'
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/default
        - name: 'argocd'
          orgId: 1
          folder: 'ArgoCD'
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/argocd
        - name: 'ingress-nginx'
          orgId: 1
          folder: 'ingress-nginx'
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/ingress-nginx
        - name: 'proxmox'
          orgId: 1
          folder: 'proxmox'
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/proxmox
  dashboards:
    argocd:
      # https://grafana.com/grafana/dashboards/19993-argocd-operational-overview/
      argocd-operational-overview:
        gnetId: 19993
        revision: 2
        datasource: prometheus
      # https://grafana.com/grafana/dashboards/19975-argocd-notifications-overview/
      argocd-notifications-overview:
        gnetId: 19975
        revision: 2
        datasource: prometheus
      # https://grafana.com/grafana/dashboards/19974-argocd-application-overview/
      argocd-application-overview:
        gnetId: 19974
        revision: 2
        datasource: prometheus
    ingress-nginx:
      # https://grafana.com/grafana/dashboards/16677-ingress-nginx-overview/
      ingress-nginx-overview:
        gnetId: 16677
        revision: 2
        datasource: prometheus
      # https://grafana.com/grafana/dashboards/20510-ingress-nginx-request-handling-performance/
      ingress-nginx-request-handling-performance:
        gnetId: 20510
        revision: 1
        datasource: prometheus
  ingress:
    enabled: true
    ingressClassName: nginx
    hosts:
      - grafana.lukehouge.com
    tls:
      - hosts:
          - grafana.lukehouge.com
        secretName: grafana-luke-tls
    annotations:
      cert-manager.io/cluster-issuer: luke-issuer

prometheus:
  ingress:
    enabled: true
    ingressClassName: nginx
    hosts:
      - prometheus.lukehouge.com
    tls:
      - hosts:
          - prometheus.lukehouge.com
        secretName: prometheus-luke-tls
    annotations:
      cert-manager.io/cluster-issuer: luke-issuer
  prometheusSpec:
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false
    probeSelectorNilUsesHelmValues: false
    ruleSelectorNilUsesHelmValues: false

    enableRemoteWriteReceiver: true
    enableFeatures:
      - exemplar-storage

    retention: 7d

    resources:
      requests:
        cpu: 2
        memory: 4Gi
      limits:
        memory: 4Gi

    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: ceph-hybrid-fs
          resources:
            requests:
              storage: 10Gi
prometheusOperator:
  resources:
    limits:
      memory: 50Mi
    requests:
      cpu: 150m
      memory: 50Mi

prometheus-node-exporter:
  resources:
    limits:
      memory: 50Mi
    requests:
      cpu: 100m
      memory: 50Mi

kube-state-metrics:
  metricLabelsAllowlist:
    - nodes=[topology.kubernetes.io/zone]
  resources:
    limits:
      memory: 50Mi
    requests:
      cpu: 100m
      memory: 50Mi

# Disable kubeProxy scraping since we disable kube-proxy to use cilium KPR
kubeProxy:
  enabled: false

# EKS does not expose controller-manager, or scheduler metrics
kubeControllerManager:
  enabled: false

kubeScheduler:
  enabled: false
