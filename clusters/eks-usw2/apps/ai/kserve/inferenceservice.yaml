apiVersion: "serving.kserve.io/v1beta1"
kind: "InferenceService"
metadata:
  name: "gpt2"
  namespace: ai
spec:
  predictor:
    model:
      modelFormat:
        name: huggingface
      args:
        - --model_name=openai-community
      storageUri: "hf://openai-community/gpt2"
      resources:
        limits:
          # cpu: "2"
          # memory: 6Gi
          nvidia.com/gpu: "1"
        requests:
          # cpu: "1"
          # memory: 4Gi
          nvidia.com/gpu: "1"